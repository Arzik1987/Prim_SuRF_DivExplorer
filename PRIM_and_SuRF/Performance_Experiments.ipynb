{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib import patches\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import shutil\n",
    "from prim_dens import PRIMdens\n",
    "from Optimization_Methods.GlowWorm import GlowWorm,GlowWormDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG,)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = range(1,6)\n",
    "size = 10**np.arange(5,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>PRIM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prim_times = []\n",
    "\n",
    "dd = None\n",
    "for d in dimensions:\n",
    "    for s in size:\n",
    "        dd = np.random.uniform(size=(s,d))\n",
    "        print(dd.shape)\n",
    "        times = []\n",
    "        for i in range(5):\n",
    "            prim = PRIMdens(dd)\n",
    "            start = time.time()\n",
    "            prim.fit()\n",
    "            end = (time.time() - start)*1000 #convert to ms\n",
    "            times.append(end)\n",
    "            print(end)\n",
    "        prim_times.append([d,s,np.mean(times), np.std(times)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(prim_times)[:,2:]/1000\n",
    "np.array(prim_times)[:,-1]/1000\n",
    "np.savetxt('output/prim_times',np.array(prim_times),delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Glowworm using approximation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regular expression to match the filename pattern\n",
    "pattern = re.compile(r'models/queries-uniform-(\\d+)-multi_False-density-XGB-RMSE=.*-R2=.*\\.pkl')\n",
    "\n",
    "# Iterate over all files in the 'models' directory\n",
    "for filename in os.listdir('models'):\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        # Extract the number from the filename\n",
    "        number = int(match.group(1))\n",
    "        \n",
    "        # Load the model from the file and set it to a global variable\n",
    "        with open(os.path.join('models', filename), 'rb') as file:\n",
    "            globals()[f'm{number}'] = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global dd\n",
    "dd = None\n",
    "glowworm_approx_details = []\n",
    "for d in dimensions:\n",
    "    for s in size:\n",
    "        dd = np.random.uniform(size=(s,d))\n",
    "        print(dd.shape)\n",
    "        if d==1:\n",
    "            m=m1\n",
    "        elif d==2:\n",
    "            m=m2\n",
    "        elif d==3:\n",
    "            m=m3\n",
    "        elif d==4:\n",
    "            m=m4\n",
    "        else:\n",
    "            m=m5\n",
    "        def objective_density(X):\n",
    "            res = np.log(m.predict(X) - 1500) - 2.9*np.sum(np.log(1+X[:,X.shape[1]//2:]),axis=1)\n",
    "            res[np.isnan(res)] = -np.inf\n",
    "            return res\n",
    "        #Generate queries\n",
    "        times = []\n",
    "        for i in range(5):\n",
    "            start = time.time()\n",
    "            gw = GlowWorm(objective_density, dimensions=2*d, nt=5, iter_max=100, glowworms=100)\n",
    "            gw.optimize()\n",
    "            end = (time.time() - start)*1000 #convert to ms\n",
    "            times.append(end)\n",
    "            print(end)\n",
    "        glowworm_approx_details.append([d,s,np.mean(times), np.std(times)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(glowworm_approx_details)[:,2:]/1000)\n",
    "np.savetxt('output/glowworm_approx_details',np.array(glowworm_approx_details),delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results post-processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim = np.loadtxt('output/prim_times', delimiter=',')\n",
    "glow_approx = np.loadtxt('output/glowworm_approx_details', delimiter=',')\n",
    "source_names = ['prim'] * prim.shape[0] + ['glow_approx'] * glow_approx.shape[0]\n",
    "data = np.column_stack((source_names, np.row_stack((prim[:,:3], glow_approx[:,:3]))))\n",
    "eval_df = pd.DataFrame(data, columns=['Source', 'Dimensions', 'Size', 'Time(ms)'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame eval_df as you mentioned before\n",
    "\n",
    "# Convert the \"Time(ms)\" column to numeric\n",
    "eval_df['Time(ms)'] = pd.to_numeric(eval_df['Time(ms)'], errors='coerce')\n",
    "\n",
    "# Divide the \"Time(ms)\" values by 1000 and round to 2 decimal places\n",
    "eval_df['Time(ms)'] = eval_df['Time(ms)'] / 1000\n",
    "eval_df['Time(ms)'] = eval_df['Time(ms)'].round(2)\n",
    "\n",
    "# Group the DataFrame by 'Source' and 'Dimensions' and aggregate the 'Time(ms)' values for each size\n",
    "grouped_df = eval_df.groupby(['Source', 'Dimensions', 'Size'])['Time(ms)'].mean().unstack(fill_value='')\n",
    "\n",
    "# Reset the index\n",
    "grouped_df = grouped_df.reset_index()\n",
    "\n",
    "# Rename the columns for sizes\n",
    "grouped_df.columns = ['Source', 'Dimensions', 'Size=100000', 'Size=1000000', 'Size=10000000']\n",
    "\n",
    "# Save the grouped DataFrame as a LaTeX table\n",
    "latex_table = grouped_df.to_latex(index=False, escape=False)\n",
    "\n",
    "# Print or save the LaTeX table\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
